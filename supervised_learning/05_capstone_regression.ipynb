{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a358db58",
   "metadata": {},
   "source": [
    "# Moduleâ€¯5 â€“ Integrated Modeling, Evaluation & Capstone Miniâ€‘Project\n",
    "Build a full endâ€‘toâ€‘end regression workflow: preprocessing pipeline, model comparison, nested crossâ€‘validation, and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fdaa7",
   "metadata": {},
   "source": [
    "## 1Â |Â Learning Objectives\n",
    "By the end of this module you will be able to:\n",
    "\n",
    "1. **Assemble** a leakageâ€‘free ML pipeline (preprocessingÂ â†’Â modelÂ â†’Â evaluation).\n",
    "2. **Select** and justify regression metrics (RMSE, MAE, RÂ²) for different goals.\n",
    "3. **Apply** robust validation (nested CV) to compare Ridge, Lasso & LightGBM fairly.\n",
    "4. **Tune** hyperâ€‘parameters efficiently (Grid/Random/Bayesian optional).\n",
    "5. **Communicate** findings in a concise, reproducible report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082577f",
   "metadata": {},
   "source": [
    "## 2Â |Â Key Concepts & Analogies\n",
    "| Concept | Plain Explanation | Analogy |\n",
    "|---------|------------------|---------|\n",
    "| **Pipeline** | Chains preprocessing + model so CV sees identical steps each fold. | Assembly line: every car (fold) goes through same stations. |\n",
    "| **Nested CV** | Inner loop tunes hyperâ€‘params; outer loop estimates generalization. | Tasteâ€‘testing (inner) with blindfolded judges (outer). |\n",
    "| **Metric Choice** | RMSE penalizes large errors; MAE robust; RÂ² relative fit. | Different grading rubrics: RMSE = harsh, MAE = lenient, RÂ² = percent score. |\n",
    "| **Baseline Model** | Simple predictor to check value of complex models. | Control group in a clinical trial. |\n",
    "| **Reproducibility** | Fix seeds, store configs, save artifacts. | Baking recipe with exact grams & oven temp. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CellÂ 1Â â€“ Imports & Settings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, json, joblib\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from lightgbm import LGBMRegressor, plot_importance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "plt.rcParams['figure.dpi'] = 110\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ce075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CellÂ 2Â â€“ Load Dataset & Split\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=0)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d5d2c",
   "metadata": {},
   "source": [
    "### 3Â |Â Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_train.assign(target=y_train).head(), X_train.describe().T.head()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1af54",
   "metadata": {},
   "source": [
    "### 4Â |Â Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb711b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes('number').columns\n",
    "categorical_cols = X.select_dtypes('object').columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ade32",
   "metadata": {},
   "source": [
    "### 5Â |Â Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16085a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([('pre', preprocessor), ('model', Ridge())])\n",
    "lasso_pipe = Pipeline([('pre', preprocessor), ('model', Lasso(max_iter=5000))])\n",
    "lgbm_pipe  = Pipeline([('pre', preprocessor), ('model', LGBMRegressor(\n",
    "    objective='regression', n_estimators=600, random_state=0, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f88ae",
   "metadata": {},
   "source": [
    "### 6Â |Â Hyperâ€‘parameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e227f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid = {'model__alpha': 10.0 ** np.arange(-3, 4)}\n",
    "lasso_grid = {'model__alpha': 10.0 ** np.arange(-3, 2)}\n",
    "lgbm_grid  = {\n",
    "    'model__num_leaves':[31, 63],\n",
    "    'model__learning_rate':[0.1, 0.05],\n",
    "    'model__min_child_samples':[10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823aa71c",
   "metadata": {},
   "source": [
    "### 7Â |Â Nested Crossâ€‘Validation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d72de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "models = {\n",
    "    'Ridge': (ridge_pipe, ridge_grid),\n",
    "    'Lasso': (lasso_pipe, lasso_grid),\n",
    "    'LightGBM': (lgbm_pipe, lgbm_grid)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, (pipe, grid) in models.items():\n",
    "    gs = GridSearchCV(pipe, grid, cv=3, scoring='neg_root_mean_squared_error')\n",
    "    cv_scores = cross_val_score(gs, X_trainval, y_trainval,\n",
    "                                cv=outer_cv, scoring='neg_root_mean_squared_error')\n",
    "    results[name] = -cv_scores  # convert to positive RMSE\n",
    "\n",
    "pd.DataFrame(results).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a8ace",
   "metadata": {},
   "source": [
    "### 8Â |Â Select Final Model & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f199338",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe, best_grid = models['LightGBM']  # choose based on previous step\n",
    "search_final = GridSearchCV(best_pipe, best_grid, cv=3,\n",
    "                           scoring='neg_root_mean_squared_error')\n",
    "search_final.fit(X_trainval, y_trainval)\n",
    "final_model = search_final.best_estimator_\n",
    "\n",
    "preds = final_model.predict(X_test)\n",
    "print('Test RMSE:', mean_squared_error(y_test, preds, squared=False))\n",
    "print('Test MAE :', mean_absolute_error(y_test, preds))\n",
    "print('Test RÂ²  :', r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80bab0",
   "metadata": {},
   "source": [
    "### 9Â |Â Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411dca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(final_model.named_steps['model'], 'feature_importances_'):\n",
    "    feats = final_model.named_steps['pre'].get_feature_names_out()\n",
    "    fi = pd.Series(final_model.named_steps['model'].feature_importances_, index=feats)\n",
    "    fi.sort_values(ascending=False)[:10].plot(kind='bar', title='TopÂ 10 Importances'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbd774",
   "metadata": {},
   "source": [
    "### 10Â |Â Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ac268",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_model, 'best_model.joblib')\n",
    "meta = {'metric':'RMSE','value': mean_squared_error(y_test, preds, squared=False)}\n",
    "with open('model_meta.json','w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5f133",
   "metadata": {},
   "source": [
    "## 11Â |Â Interactive Checkpoints\n",
    "### 11.1 Quick Quiz âœ…\n",
    "*Q:* Which metric is most sensitive to extreme errors and why?  \n",
    "\n",
    "### 11.2 Coding Exercise ğŸ’»  \n",
    "Implement `RandomizedSearchCV` for LightGBM; compare runtime and RMSE with gridâ€‘search above.\n",
    "\n",
    "### 11.3 Reflection âœï¸  \n",
    "*When might a linear model beat LightGBM in production? Consider data size, feature sparsity, interpretability, and latency.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba22736",
   "metadata": {},
   "source": [
    "## 12Â |Â Readings & Resources\n",
    "* **scikitâ€‘learn docs** â€“ Evaluation, Crossâ€‘Validation, Pipelines\n",
    "* Varoquaux (2018) â€“ â€œCrossâ€‘validation pitfalls and how to avoid themâ€\n",
    "* Optuna â€“ Hyperparameter Optimization intro\n",
    "* Blog â€“ â€œNested CV vs Train/Test/Valâ€ (Sebastian Raschka)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee5e15",
   "metadata": {},
   "source": [
    "## 13Â |Â Optional Advanced Challenge ğŸŒŸ\n",
    "1. **Bayesian Optimization with Optuna**: optimize LightGBM RMSE & training time.\n",
    "2. **Prediction Intervals**: build ensemble of seeds; compute mean Â± 1.96Ã—std.\n",
    "3. **Deployment Sketch**: serialize pipeline & create FastAPI endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b57e9",
   "metadata": {},
   "source": [
    "## 14Â |Â Completion Checklist âœ…\n",
    "* Leakageâ€‘free pipeline built.\n",
    "* Nested CV comparison complete.\n",
    "* Metrics chosen & justified.\n",
    "* Best model saved (`best_model.joblib`) with metadata.\n",
    "* Interpretation plot produced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
