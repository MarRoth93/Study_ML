{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a358db58",
   "metadata": {},
   "source": [
    "# Module 5 – Integrated Modeling, Evaluation & Capstone Mini‑Project\n",
    "Build a full end‑to‑end regression workflow: preprocessing pipeline, model comparison, nested cross‑validation, and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fdaa7",
   "metadata": {},
   "source": [
    "## 1 | Learning Objectives\n",
    "By the end of this module you will be able to:\n",
    "\n",
    "1. **Assemble** a leakage‑free ML pipeline (preprocessing → model → evaluation).\n",
    "2. **Select** and justify regression metrics (RMSE, MAE, R²) for different goals.\n",
    "3. **Apply** robust validation (nested CV) to compare Ridge, Lasso & LightGBM fairly.\n",
    "4. **Tune** hyper‑parameters efficiently (Grid/Random/Bayesian optional).\n",
    "5. **Communicate** findings in a concise, reproducible report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082577f",
   "metadata": {},
   "source": [
    "## 2 | Key Concepts & Analogies\n",
    "| Concept | Plain Explanation | Analogy |\n",
    "|---------|------------------|---------|\n",
    "| **Pipeline** | Chains preprocessing + model so CV sees identical steps each fold. | Assembly line: every car (fold) goes through same stations. |\n",
    "| **Nested CV** | Inner loop tunes hyper‑params; outer loop estimates generalization. | Taste‑testing (inner) with blindfolded judges (outer). |\n",
    "| **Metric Choice** | RMSE penalizes large errors; MAE robust; R² relative fit. | Different grading rubrics: RMSE = harsh, MAE = lenient, R² = percent score. |\n",
    "| **Baseline Model** | Simple predictor to check value of complex models. | Control group in a clinical trial. |\n",
    "| **Reproducibility** | Fix seeds, store configs, save artifacts. | Baking recipe with exact grams & oven temp. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 – Imports & Settings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, json, joblib\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from lightgbm import LGBMRegressor, plot_importance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "plt.rcParams['figure.dpi'] = 110\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ce075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 – Load Dataset & Split\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=0)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d5d2c",
   "metadata": {},
   "source": [
    "### 3 | Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_train.assign(target=y_train).head(), X_train.describe().T.head()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1af54",
   "metadata": {},
   "source": [
    "### 4 | Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb711b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes('number').columns\n",
    "categorical_cols = X.select_dtypes('object').columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ade32",
   "metadata": {},
   "source": [
    "### 5 | Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16085a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([('pre', preprocessor), ('model', Ridge())])\n",
    "lasso_pipe = Pipeline([('pre', preprocessor), ('model', Lasso(max_iter=5000))])\n",
    "lgbm_pipe  = Pipeline([('pre', preprocessor), ('model', LGBMRegressor(\n",
    "    objective='regression', n_estimators=600, random_state=0, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f88ae",
   "metadata": {},
   "source": [
    "### 6 | Hyper‑parameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e227f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid = {'model__alpha': 10.0 ** np.arange(-3, 4)}\n",
    "lasso_grid = {'model__alpha': 10.0 ** np.arange(-3, 2)}\n",
    "lgbm_grid  = {\n",
    "    'model__num_leaves':[31, 63],\n",
    "    'model__learning_rate':[0.1, 0.05],\n",
    "    'model__min_child_samples':[10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823aa71c",
   "metadata": {},
   "source": [
    "### 7 | Nested Cross‑Validation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d72de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "models = {\n",
    "    'Ridge': (ridge_pipe, ridge_grid),\n",
    "    'Lasso': (lasso_pipe, lasso_grid),\n",
    "    'LightGBM': (lgbm_pipe, lgbm_grid)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, (pipe, grid) in models.items():\n",
    "    gs = GridSearchCV(pipe, grid, cv=3, scoring='neg_root_mean_squared_error')\n",
    "    cv_scores = cross_val_score(gs, X_trainval, y_trainval,\n",
    "                                cv=outer_cv, scoring='neg_root_mean_squared_error')\n",
    "    results[name] = -cv_scores  # convert to positive RMSE\n",
    "\n",
    "pd.DataFrame(results).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a8ace",
   "metadata": {},
   "source": [
    "### 8 | Select Final Model & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f199338",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe, best_grid = models['LightGBM']  # choose based on previous step\n",
    "search_final = GridSearchCV(best_pipe, best_grid, cv=3,\n",
    "                           scoring='neg_root_mean_squared_error')\n",
    "search_final.fit(X_trainval, y_trainval)\n",
    "final_model = search_final.best_estimator_\n",
    "\n",
    "preds = final_model.predict(X_test)\n",
    "print('Test RMSE:', mean_squared_error(y_test, preds, squared=False))\n",
    "print('Test MAE :', mean_absolute_error(y_test, preds))\n",
    "print('Test R²  :', r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80bab0",
   "metadata": {},
   "source": [
    "### 9 | Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411dca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(final_model.named_steps['model'], 'feature_importances_'):\n",
    "    feats = final_model.named_steps['pre'].get_feature_names_out()\n",
    "    fi = pd.Series(final_model.named_steps['model'].feature_importances_, index=feats)\n",
    "    fi.sort_values(ascending=False)[:10].plot(kind='bar', title='Top 10 Importances'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbd774",
   "metadata": {},
   "source": [
    "### 10 | Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ac268",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_model, 'best_model.joblib')\n",
    "meta = {'metric':'RMSE','value': mean_squared_error(y_test, preds, squared=False)}\n",
    "with open('model_meta.json','w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5f133",
   "metadata": {},
   "source": [
    "## 11 | Interactive Checkpoints\n",
    "### 11.1 Quick Quiz ✅\n",
    "*Q:* Which metric is most sensitive to extreme errors and why?  \n",
    "\n",
    "### 11.2 Coding Exercise 💻  \n",
    "Implement `RandomizedSearchCV` for LightGBM; compare runtime and RMSE with grid‑search above.\n",
    "\n",
    "### 11.3 Reflection ✍️  \n",
    "*When might a linear model beat LightGBM in production? Consider data size, feature sparsity, interpretability, and latency.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba22736",
   "metadata": {},
   "source": [
    "## 12 | Readings & Resources\n",
    "* **scikit‑learn docs** – Evaluation, Cross‑Validation, Pipelines\n",
    "* Varoquaux (2018) – “Cross‑validation pitfalls and how to avoid them”\n",
    "* Optuna – Hyperparameter Optimization intro\n",
    "* Blog – “Nested CV vs Train/Test/Val” (Sebastian Raschka)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee5e15",
   "metadata": {},
   "source": [
    "## 13 | Optional Advanced Challenge 🌟\n",
    "1. **Bayesian Optimization with Optuna**: optimize LightGBM RMSE & training time.\n",
    "2. **Prediction Intervals**: build ensemble of seeds; compute mean ± 1.96×std.\n",
    "3. **Deployment Sketch**: serialize pipeline & create FastAPI endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b57e9",
   "metadata": {},
   "source": [
    "## 14 | Completion Checklist ✅\n",
    "* Leakage‑free pipeline built.\n",
    "* Nested CV comparison complete.\n",
    "* Metrics chosen & justified.\n",
    "* Best model saved (`best_model.joblib`) with metadata.\n",
    "* Interpretation plot produced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
