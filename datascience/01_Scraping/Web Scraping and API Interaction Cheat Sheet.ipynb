{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping and API Interaction Cheat Sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "href: https://example.com\n"
     ]
    }
   ],
   "source": [
    "# Accessing element attribute\n",
    "# Access the value of a specific attribute of an HTML element.\n",
    "# Syntax:\n",
    "# attribute = element[attribute]\n",
    "# Example:\n",
    "html = '<a href=\"https://example.com\">Example</a>'\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "link_element = soup.find('a')\n",
    "href = link_element['href']\n",
    "print(f'href: {href}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup()\n",
    "# Parse the HTML content of a web page using BeautifulSoup.\n",
    "# Syntax:\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "# Example:\n",
    "html = requests.get('https://example.com').text\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First link: None\n"
     ]
    }
   ],
   "source": [
    "# find()\n",
    "# Find the first HTML element that matches the specified tag and attributes.\n",
    "# Syntax:\n",
    "# element = soup.find(tag, attrs)\n",
    "# Example:\n",
    "first_link = soup.find('a', {'class': 'link'})\n",
    "print(f'First link: {first_link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "href: https://example.com\n",
      "First link: None\n",
      "All links: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findChildren'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# findChildren()\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Find all child elements of an HTML element.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Syntax:\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# children = element.findChildren()\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m     56\u001b[0m parent_div \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparent\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 57\u001b[0m child_elements \u001b[38;5;241m=\u001b[39m \u001b[43mparent_div\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindChildren\u001b[49m()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChild elements: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_elements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# get()\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Perform a GET request to retrieve data from a specified URL.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Syntax:\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# response = requests.get(url)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findChildren'"
     ]
    }
   ],
   "source": [
    "# Web Scraping and API Interaction Cheat Sheet\n",
    "\n",
    "## Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Accessing element attribute\n",
    "# Access the value of a specific attribute of an HTML element.\n",
    "# Syntax:\n",
    "# attribute = element[attribute]\n",
    "# Example:\n",
    "html = '<a href=\"https://example.com\">Example</a>'\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "link_element = soup.find('a')\n",
    "href = link_element['href']\n",
    "print(f'href: {href}')\n",
    "\n",
    "# BeautifulSoup()\n",
    "# Parse the HTML content of a web page using BeautifulSoup.\n",
    "# Syntax:\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "# Example:\n",
    "html = requests.get('https://example.com').text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# delete()\n",
    "# Send a DELETE request to remove data or a resource from the server.\n",
    "# Syntax:\n",
    "# response = requests.delete(url)\n",
    "# Example:\n",
    "# response = requests.delete('https://api.example.com/delete')\n",
    "\n",
    "# find()\n",
    "# Find the first HTML element that matches the specified tag and attributes.\n",
    "# Syntax:\n",
    "# element = soup.find(tag, attrs)\n",
    "# Example:\n",
    "first_link = soup.find('a', {'class': 'link'})\n",
    "print(f'First link: {first_link}')\n",
    "\n",
    "# find_all()\n",
    "# Find all HTML elements that match the specified tag and attributes.\n",
    "# Syntax:\n",
    "# elements = soup.find_all(tag, attrs)\n",
    "# Example:\n",
    "all_links = soup.find_all('a', {'class': 'link'})\n",
    "print(f'All links: {all_links}')\n",
    "\n",
    "# findChildren()\n",
    "# Find all child elements of an HTML element.\n",
    "# Syntax:\n",
    "# children = element.findChildren()\n",
    "# Example:\n",
    "parent_div = soup.find('div', {'id': 'parent'})\n",
    "child_elements = parent_div.findChildren()\n",
    "print(f'Child elements: {child_elements}')\n",
    "\n",
    "# get()\n",
    "# Perform a GET request to retrieve data from a specified URL.\n",
    "# Syntax:\n",
    "# response = requests.get(url)\n",
    "# Example:\n",
    "url = 'https://api.example.com/data'\n",
    "response = requests.get(url)\n",
    "print(f'Response: {response.text}')\n",
    "\n",
    "# Headers\n",
    "# Include custom headers in the request.\n",
    "# Syntax:\n",
    "# headers = {'HeaderName': 'Value'}\n",
    "# Example:\n",
    "base_url = 'https://api.example.com/data'\n",
    "headers = {'Authorization': 'Bearer YOUR_TOKEN'}\n",
    "response = requests.get(base_url, headers=headers)\n",
    "print(f'Response with headers: {response.text}')\n",
    "\n",
    "# json()\n",
    "# Parse JSON data from the response.\n",
    "# Syntax:\n",
    "# data = response.json()\n",
    "# Example:\n",
    "response = requests.get('https://api.example.com/data')\n",
    "data = response.json()\n",
    "print(f'JSON data: {data}')\n",
    "\n",
    "# next_sibling()\n",
    "# Find the next sibling element in the DOM.\n",
    "# Syntax:\n",
    "# sibling = element.find_next_sibling()\n",
    "# Example:\n",
    "current_element = soup.find('p')\n",
    "next_sibling = current_element.find_next_sibling()\n",
    "print(f'Next sibling: {next_sibling}')\n",
    "\n",
    "# parent\n",
    "# Access the parent element in the Document Object Model (DOM).\n",
    "# Syntax:\n",
    "# parent = element.parent\n",
    "# Example:\n",
    "paragraph = soup.find('p')\n",
    "parent_div = paragraph.parent\n",
    "print(f'Parent element: {parent_div}')\n",
    "\n",
    "# post()\n",
    "# Send a POST request to a specified URL with data.\n",
    "# Syntax:\n",
    "# response = requests.post(url, data)\n",
    "# Example:\n",
    "url = 'https://api.example.com/submit'\n",
    "data = {'key': 'value'}\n",
    "response = requests.post(url, data=data)\n",
    "print(f'POST response: {response.text}')\n",
    "\n",
    "# put()\n",
    "# Send a PUT request to update data on the server.\n",
    "# Syntax:\n",
    "# response = requests.put(url, data)\n",
    "# Example:\n",
    "url = 'https://api.example.com/update'\n",
    "data = {'key': 'value'}\n",
    "response = requests.put(url, data=data)\n",
    "print(f'PUT response: {response.text}')\n",
    "\n",
    "# Query parameters\n",
    "# Pass query parameters in the URL to filter or customize the request.\n",
    "# Syntax:\n",
    "# params = {'param_name': 'value'}\n",
    "# Example:\n",
    "base_url = 'https://api.example.com/data'\n",
    "params = {'page': 1, 'per_page': 10}\n",
    "response = requests.get(base_url, params=params)\n",
    "print(f'Response with query parameters: {response.text}')\n",
    "\n",
    "# select()\n",
    "# Select HTML elements from the parsed HTML using a CSS selector.\n",
    "# Syntax:\n",
    "# element = soup.select(selector)\n",
    "# Example:\n",
    "titles = soup.select('h1')\n",
    "print(f'Titles: {titles}')\n",
    "\n",
    "# status_code\n",
    "# Check the HTTP status code of the response.\n",
    "# Syntax:\n",
    "# response.status_code\n",
    "# Example:\n",
    "url = 'https://api.example.com/data'\n",
    "response = requests.get(url)\n",
    "status_code = response.status_code\n",
    "print(f'Status code: {status_code}')\n",
    "\n",
    "# tags for find() and find_all()\n",
    "# Specify any valid HTML tag as the tag parameter to search for elements of that type.\n",
    "# Example:\n",
    "tags = ['a', 'p', 'h1', 'table', 'tr', 'td', 'th', 'img', 'form', 'button']\n",
    "\n",
    "# text\n",
    "# Retrieve the text content of an HTML element.\n",
    "# Syntax:\n",
    "# text = element.text\n",
    "# Example:\n",
    "title_element = soup.find('h1')\n",
    "title_text = title_element.text\n",
    "print(f'Title text: {title_text}')\n",
    "\n",
    "# Opening an image using PIL\n",
    "# URL of the image\n",
    "image_url = \"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\"\n",
    "# Download the image\n",
    "image_response = requests.get(image_url)\n",
    "img_data = image_response.content\n",
    "# Open the image with Pillow\n",
    "image = Image.open(BytesIO(img_data))\n",
    "# Display the image\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
