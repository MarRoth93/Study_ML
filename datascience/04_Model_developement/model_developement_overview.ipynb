{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a492971f",
   "metadata": {},
   "source": [
    "# Comprehensive Model Development Guide\n",
    "\n",
    "Welcome to this complete educational guide on **Machine Learning Model Development**! This notebook covers everything from basic regression to advanced model evaluation and refinement techniques.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will master:\n",
    "\n",
    "1. **Regression Techniques** - Simple, Multiple, and Polynomial Regression\n",
    "2. **Feature Engineering** - Transformation, scaling, and polynomial features\n",
    "3. **Model Evaluation** - MSE, R¬≤, residual analysis, and diagnostic plots\n",
    "4. **Model Validation** - Train-test splits and cross-validation\n",
    "5. **Overfitting & Underfitting** - Bias-variance tradeoff and model selection\n",
    "6. **Regularization** - Ridge regression and hyperparameter tuning\n",
    "7. **Pipeline Development** - End-to-end ML workflows\n",
    "8. **Real-world Applications** - Practical examples with automotive data\n",
    "\n",
    "## üìä What We'll Build\n",
    "\n",
    "We'll develop predictive models for **car price prediction** using various regression techniques, demonstrating the complete machine learning workflow from data preprocessing to model deployment.\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin our comprehensive journey into model development!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Library Imports for Model Development\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Imports\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üöÄ Ready for comprehensive model development!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ff3ab",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n",
    "\n",
    "The foundation of any successful machine learning project is quality data. Let's load our automotive dataset and prepare it for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the automotive dataset\n",
    "# Using the cleaned dataset from our data analysis module\n",
    "df = pd.read_csv('../03_Data_analysis/clean_df.csv', index_col=0)\n",
    "\n",
    "print(\"üéâ Dataset loaded successfully!\")\n",
    "print(f\"üìä Dataset dimensions: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\nüìã Dataset Overview:\")\n",
    "print(f\"‚Ä¢ Target variable: price\")\n",
    "print(f\"‚Ä¢ Features available: {df.shape[1] - 1}\")\n",
    "print(f\"‚Ä¢ Data types: {df.dtypes.value_counts().to_dict()}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nüîç First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "print(\"üîß PREPARING FEATURES FOR MODELING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select numerical features for modeling\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'price' in numerical_features:\n",
    "    numerical_features.remove('price')\n",
    "\n",
    "print(f\"üìä Available numerical features: {len(numerical_features)}\")\n",
    "print(f\"Features: {numerical_features}\")\n",
    "\n",
    "# Select key features based on domain knowledge and previous analysis\n",
    "key_features = ['engine-size', 'curb-weight', 'horsepower', 'highway-mpg', 'wheel-base']\n",
    "# Use available features from the dataset\n",
    "selected_features = [col for col in key_features if col in df.columns]\n",
    "\n",
    "if not selected_features:\n",
    "    # If key features not available, use first few numerical features\n",
    "    selected_features = numerical_features[:5]\n",
    "\n",
    "print(f\"\\nüéØ Selected features for modeling: {selected_features}\")\n",
    "\n",
    "# Prepare feature matrix (X) and target vector (y)\n",
    "X = df[selected_features].copy()\n",
    "y = df['price'].copy()\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nüîç Data Quality Check:\")\n",
    "print(f\"‚Ä¢ Missing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"‚Ä¢ Missing values in target: {y.isnull().sum()}\")\n",
    "\n",
    "# Handle missing values if any\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"‚ö†Ô∏è Handling missing values with median imputation\")\n",
    "    X = X.fillna(X.median())\n",
    "\n",
    "if y.isnull().sum() > 0:\n",
    "    print(\"‚ö†Ô∏è Removing rows with missing target values\")\n",
    "    mask = ~y.isnull()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "print(f\"\\n‚úÖ Final dataset ready:\")\n",
    "print(f\"‚Ä¢ Features shape: {X.shape}\")\n",
    "print(f\"‚Ä¢ Target shape: {y.shape}\")\n",
    "print(f\"‚Ä¢ Feature statistics:\")\n",
    "print(X.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b5aa6",
   "metadata": {},
   "source": [
    "## 2. Simple Linear Regression\n",
    "\n",
    "**Simple Linear Regression** models the relationship between a single independent variable and a dependent variable using a linear equation:\n",
    "\n",
    "**y = Œ≤‚ÇÄ + Œ≤‚ÇÅx + Œµ**\n",
    "\n",
    "Where:\n",
    "- **y**: Dependent variable (price)\n",
    "- **x**: Independent variable (feature)\n",
    "- **Œ≤‚ÇÄ**: Intercept (y-axis crossing point)\n",
    "- **Œ≤‚ÇÅ**: Slope (rate of change)\n",
    "- **Œµ**: Error term\n",
    "\n",
    "Let's start with modeling price using engine size as our single predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76000e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Linear Regression - Using Engine Size to Predict Price\n",
    "print(\"üîç SIMPLE LINEAR REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select the best single feature for demonstration\n",
    "if 'engine-size' in X.columns:\n",
    "    feature_name = 'engine-size'\n",
    "elif len(selected_features) > 0:\n",
    "    feature_name = selected_features[0]\n",
    "else:\n",
    "    feature_name = X.columns[0]\n",
    "\n",
    "X_simple = X[[feature_name]].copy()\n",
    "print(f\"üéØ Predicting price using: {feature_name}\")\n",
    "\n",
    "# Create and fit the model\n",
    "model_simple = LinearRegression()\n",
    "model_simple.fit(X_simple, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_simple = model_simple.predict(X_simple)\n",
    "\n",
    "# Extract model parameters\n",
    "intercept = model_simple.intercept_\n",
    "slope = model_simple.coef_[0]\n",
    "\n",
    "print(f\"\\nüìä Model Equation:\")\n",
    "print(f\"price = {intercept:.2f} + {slope:.2f} √ó {feature_name}\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse_simple = mean_squared_error(y, y_pred_simple)\n",
    "r2_simple = r2_score(y, y_pred_simple)\n",
    "rmse_simple = np.sqrt(mse_simple)\n",
    "\n",
    "print(f\"\\nüìà Model Performance:\")\n",
    "print(f\"‚Ä¢ R¬≤ Score: {r2_simple:.4f} ({r2_simple*100:.1f}% variance explained)\")\n",
    "print(f\"‚Ä¢ RMSE: ${rmse_simple:,.2f}\")\n",
    "print(f\"‚Ä¢ MSE: {mse_simple:,.2f}\")\n",
    "\n",
    "# Visualize the regression\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Scatter plot with regression line\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_simple, y, alpha=0.6, color='blue', s=30)\n",
    "plt.plot(X_simple, y_pred_simple, color='red', linewidth=2, label=f'Regression Line')\n",
    "plt.xlabel(feature_name, fontweight='bold')\n",
    "plt.ylabel('Price ($)', fontweight='bold')\n",
    "plt.title(f'Simple Linear Regression\\n{feature_name} vs Price', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y - y_pred_simple\n",
    "plt.scatter(y_pred_simple, residuals, alpha=0.6, color='green', s=30)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Price ($)', fontweight='bold')\n",
    "plt.ylabel('Residuals', fontweight='bold')\n",
    "plt.title('Residual Plot', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"‚Ä¢ For every unit increase in {feature_name}, price increases by ${slope:.2f}\")\n",
    "print(f\"‚Ä¢ Model explains {r2_simple*100:.1f}% of price variation\")\n",
    "print(f\"‚Ä¢ {'Strong' if r2_simple > 0.7 else 'Moderate' if r2_simple > 0.4 else 'Weak'} relationship observed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fbb7a",
   "metadata": {},
   "source": [
    "## 3. Multiple Linear Regression\n",
    "\n",
    "**Multiple Linear Regression** extends simple regression to use multiple independent variables:\n",
    "\n",
    "**y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ**\n",
    "\n",
    "This allows us to capture more complex relationships and typically provides better predictions by considering multiple factors simultaneously.\n",
    "\n",
    "### Advantages of Multiple Linear Regression:\n",
    "- **Better Predictions**: Uses more information\n",
    "- **Feature Importance**: Shows relative impact of each variable\n",
    "- **Real-world Modeling**: Most real phenomena depend on multiple factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eddff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression - Using All Selected Features\n",
    "print(\"üîç MULTIPLE LINEAR REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use all selected features\n",
    "X_multiple = X[selected_features].copy()\n",
    "print(f\"üéØ Predicting price using {len(selected_features)} features:\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    print(f\"   {i}. {feature}\")\n",
    "\n",
    "# Create and fit the model\n",
    "model_multiple = LinearRegression()\n",
    "model_multiple.fit(X_multiple, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_multiple = model_multiple.predict(X_multiple)\n",
    "\n",
    "# Extract model parameters\n",
    "intercept_mult = model_multiple.intercept_\n",
    "coefficients = model_multiple.coef_\n",
    "\n",
    "print(f\"\\nüìä Model Equation:\")\n",
    "equation = f\"price = {intercept_mult:.2f}\"\n",
    "for feature, coef in zip(selected_features, coefficients):\n",
    "    equation += f\" + ({coef:.2f} √ó {feature})\"\n",
    "print(equation)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse_multiple = mean_squared_error(y, y_pred_multiple)\n",
    "r2_multiple = r2_score(y, y_pred_multiple)\n",
    "rmse_multiple = np.sqrt(mse_multiple)\n",
    "\n",
    "print(f\"\\nüìà Model Performance:\")\n",
    "print(f\"‚Ä¢ R¬≤ Score: {r2_multiple:.4f} ({r2_multiple*100:.1f}% variance explained)\")\n",
    "print(f\"‚Ä¢ RMSE: ${rmse_multiple:,.2f}\")\n",
    "print(f\"‚Ä¢ MSE: {mse_multiple:,.2f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nüéØ Feature Importance (by absolute coefficient):\")\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    impact = \"Positive\" if row['Coefficient'] > 0 else \"Negative\"\n",
    "    print(f\"‚Ä¢ {row['Feature']:15}: {row['Coefficient']:8.2f} ({impact} impact)\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0, 0].scatter(y, y_pred_multiple, alpha=0.6, color='blue', s=30)\n",
    "axes[0, 0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Actual Price ($)', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Predicted Price ($)', fontweight='bold')\n",
    "axes[0, 0].set_title(f'Actual vs Predicted\\nR¬≤ = {r2_multiple:.3f}', fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals vs Predicted\n",
    "residuals_mult = y - y_pred_multiple\n",
    "axes[0, 1].scatter(y_pred_multiple, residuals_mult, alpha=0.6, color='green', s=30)\n",
    "axes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Predicted Price ($)', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Residuals', fontweight='bold')\n",
    "axes[0, 1].set_title('Residual Plot', fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance\n",
    "axes[1, 0].barh(feature_importance['Feature'], feature_importance['Abs_Coefficient'], \n",
    "                color='orange', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Absolute Coefficient Value', fontweight='bold')\n",
    "axes[1, 0].set_title('Feature Importance', fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distribution of residuals\n",
    "axes[1, 1].hist(residuals_mult, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[1, 1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Residuals', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Frequency', fontweight='bold')\n",
    "axes[1, 1].set_title('Distribution of Residuals', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare with simple linear regression\n",
    "print(f\"\\nüìä MODEL COMPARISON:\")\n",
    "print(f\"{'Metric':<15} {'Simple LR':<12} {'Multiple LR':<12} {'Improvement':<12}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'R¬≤ Score':<15} {r2_simple:<12.4f} {r2_multiple:<12.4f} {((r2_multiple-r2_simple)/r2_simple*100):+8.1f}%\")\n",
    "print(f\"{'RMSE':<15} {rmse_simple:<12,.0f} {rmse_multiple:<12,.0f} {((rmse_multiple-rmse_simple)/rmse_simple*100):+8.1f}%\")\n",
    "\n",
    "improvement = r2_multiple > r2_simple\n",
    "print(f\"\\n‚úÖ Multiple Linear Regression {'performs better' if improvement else 'needs improvement'}\")\n",
    "print(f\"üìà Additional features explain {(r2_multiple-r2_simple)*100:.1f}% more variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d0d3c",
   "metadata": {},
   "source": [
    "## 4. Polynomial Regression\n",
    "\n",
    "**Polynomial Regression** captures non-linear relationships by using polynomial features. Instead of just x, we use x, x¬≤, x¬≥, etc.\n",
    "\n",
    "**For degree 2: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx + Œ≤‚ÇÇx¬≤ + Œµ**\n",
    "\n",
    "### When to Use Polynomial Regression:\n",
    "- **Non-linear relationships** between variables\n",
    "- **Curved patterns** in scatter plots\n",
    "- **Improve model fit** when linear relationship is insufficient\n",
    "\n",
    "### Key Considerations:\n",
    "- **Higher degrees** can lead to overfitting\n",
    "- **Feature scaling** becomes more important\n",
    "- **Interpretation** becomes more complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression - Capturing Non-linear Relationships\n",
    "print(\"üîç POLYNOMIAL REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different polynomial degrees\n",
    "degrees = [1, 2, 3, 4]\n",
    "poly_results = []\n",
    "\n",
    "# Use single feature for polynomial demonstration\n",
    "X_poly_single = X_simple.copy()\n",
    "print(f\"üéØ Creating polynomial features for: {feature_name}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    print(f\"\\nüìä Testing Polynomial Degree {degree}:\")\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly_features.fit_transform(X_poly_single)\n",
    "    \n",
    "    # Create and fit model\n",
    "    model_poly = LinearRegression()\n",
    "    model_poly.fit(X_poly, y)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_poly = model_poly.predict(X_poly)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_poly = mean_squared_error(y, y_pred_poly)\n",
    "    r2_poly = r2_score(y, y_pred_poly)\n",
    "    rmse_poly = np.sqrt(mse_poly)\n",
    "    \n",
    "    # Store results\n",
    "    poly_results.append({\n",
    "        'Degree': degree,\n",
    "        'R2': r2_poly,\n",
    "        'RMSE': rmse_poly,\n",
    "        'MSE': mse_poly,\n",
    "        'Features': X_poly.shape[1]\n",
    "    })\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Features created: {X_poly.shape[1]}\")\n",
    "    print(f\"   ‚Ä¢ R¬≤ Score: {r2_poly:.4f}\")\n",
    "    print(f\"   ‚Ä¢ RMSE: ${rmse_poly:,.2f}\")\n",
    "    \n",
    "    # Create smooth line for visualization\n",
    "    X_range = np.linspace(X_poly_single.min(), X_poly_single.max(), 300).reshape(-1, 1)\n",
    "    X_range_poly = poly_features.transform(X_range)\n",
    "    y_range_pred = model_poly.predict(X_range_poly)\n",
    "    \n",
    "    # Plot\n",
    "    axes[i].scatter(X_poly_single, y, alpha=0.6, color='blue', s=20, label='Data')\n",
    "    axes[i].plot(X_range, y_range_pred, color='red', linewidth=2, label=f'Degree {degree}')\n",
    "    axes[i].set_xlabel(feature_name, fontweight='bold')\n",
    "    axes[i].set_ylabel('Price ($)', fontweight='bold')\n",
    "    axes[i].set_title(f'Polynomial Degree {degree}\\nR¬≤ = {r2_poly:.3f}', fontweight='bold')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Results comparison\n",
    "poly_df = pd.DataFrame(poly_results)\n",
    "print(f\"\\nüìä POLYNOMIAL REGRESSION COMPARISON:\")\n",
    "print(poly_df.round(4))\n",
    "\n",
    "# Plot comparison metrics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# R¬≤ comparison\n",
    "axes[0].plot(poly_df['Degree'], poly_df['R2'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Polynomial Degree', fontweight='bold')\n",
    "axes[0].set_ylabel('R¬≤ Score', fontweight='bold')\n",
    "axes[0].set_title('R¬≤ Score vs Polynomial Degree', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(degrees)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[1].plot(poly_df['Degree'], poly_df['RMSE'], 'ro-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Polynomial Degree', fontweight='bold')\n",
    "axes[1].set_ylabel('RMSE ($)', fontweight='bold')\n",
    "axes[1].set_title('RMSE vs Polynomial Degree', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(degrees)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best degree\n",
    "best_poly = poly_df.loc[poly_df['R2'].idxmax()]\n",
    "print(f\"\\nüèÜ BEST POLYNOMIAL DEGREE: {int(best_poly['Degree'])}\")\n",
    "print(f\"‚Ä¢ R¬≤ Score: {best_poly['R2']:.4f}\")\n",
    "print(f\"‚Ä¢ RMSE: ${best_poly['RMSE']:,.2f}\")\n",
    "print(f\"‚Ä¢ Features created: {int(best_poly['Features'])}\")\n",
    "\n",
    "# Warning about overfitting\n",
    "if best_poly['Degree'] > 3:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: High polynomial degree ({int(best_poly['Degree'])}) may indicate overfitting!\")\n",
    "    print(\"   Consider using regularization or cross-validation.\")\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "print(f\"‚Ä¢ Polynomial features can capture non-linear relationships\")\n",
    "print(f\"‚Ä¢ Higher degrees increase model complexity\")\n",
    "print(f\"‚Ä¢ Balance between fit improvement and overfitting risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0f5ee",
   "metadata": {},
   "source": [
    "## 5. Feature Transformation and Scaling\n",
    "\n",
    "**Feature scaling** is crucial for machine learning algorithms, especially when features have different scales or when using polynomial features.\n",
    "\n",
    "### Why Feature Scaling Matters:\n",
    "- **Different scales**: Features like price ($) vs. mileage (mpg) have vastly different ranges\n",
    "- **Algorithm performance**: Many ML algorithms are sensitive to feature scales\n",
    "- **Gradient descent**: Converges faster with scaled features\n",
    "- **Regularization**: Works better when features are on similar scales\n",
    "\n",
    "### Common Scaling Methods:\n",
    "- **StandardScaler**: Mean = 0, Standard Deviation = 1\n",
    "- **MinMaxScaler**: Scale to [0, 1] range\n",
    "- **RobustScaler**: Uses median and quartiles (robust to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13edf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and target\n",
    "features = ['highway-mpg', 'engine-size', 'horsepower', 'curb-weight']\n",
    "X = df_clean[features].copy()\n",
    "y = df_clean['price']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Original feature ranges:\")\n",
    "print(X_train.describe())\n",
    "\n",
    "# Apply different scaling methods\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Original data distribution\n",
    "axes[0].boxplot([X_train[col] for col in features], labels=features)\n",
    "axes[0].set_title('Original Features')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Apply and visualize each scaler\n",
    "for idx, (name, scaler) in enumerate(scalers.items(), 1):\n",
    "    X_scaled = scaler.fit_transform(X_train)\n",
    "    axes[idx].boxplot([X_scaled[:, i] for i in range(len(features))], labels=features)\n",
    "    axes[idx].set_title(f'{name}')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare model performance with different scalers\n",
    "print(\"\\nModel Performance Comparison with Different Scalers:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, scaler in scalers.items():\n",
    "    # Scale the training data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Train R¬≤: {train_r2:.4f}, Test R¬≤: {test_r2:.4f}\")\n",
    "    print(f\"  Train RMSE: ${train_rmse:,.0f}, Test RMSE: ${test_rmse:,.0f}\")\n",
    "    print()\n",
    "\n",
    "# Without scaling (baseline)\n",
    "model_baseline = LinearRegression()\n",
    "model_baseline.fit(X_train, y_train)\n",
    "y_train_pred = model_baseline.predict(X_train)\n",
    "y_test_pred = model_baseline.predict(X_test)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(\"No Scaling (Baseline):\")\n",
    "print(f\"  Train R¬≤: {train_r2:.4f}, Test R¬≤: {test_r2:.4f}\")\n",
    "print(f\"  Train RMSE: ${train_rmse:,.0f}, Test RMSE: ${test_rmse:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463d0af",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Validation\n",
    "\n",
    "**Model evaluation** is critical to understand how well your model performs and whether it generalizes to new data.\n",
    "\n",
    "### Key Evaluation Metrics for Regression:\n",
    "\n",
    "1. **R-squared (R¬≤)**: Proportion of variance explained by the model\n",
    "   - Range: 0 to 1 (higher is better)\n",
    "   - R¬≤ = 1 - (SS_res / SS_tot)\n",
    "\n",
    "2. **Mean Squared Error (MSE)**: Average of squared differences\n",
    "   - Lower is better\n",
    "   - Sensitive to outliers\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**: Square root of MSE\n",
    "   - Same units as target variable\n",
    "   - Easy to interpret\n",
    "\n",
    "4. **Mean Absolute Error (MAE)**: Average of absolute differences\n",
    "   - Less sensitive to outliers than MSE\n",
    "   - Robust metric\n",
    "\n",
    "### Cross-Validation:\n",
    "- **Purpose**: Get more reliable performance estimates\n",
    "- **K-Fold CV**: Split data into k folds, train on k-1, test on 1\n",
    "- **Benefits**: Reduces overfitting to specific train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare data with standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    \"\"\"Calculate and print regression metrics\"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"{dataset_name} Metrics:\")\n",
    "    print(f\"  R¬≤: {r2:.4f}\")\n",
    "    print(f\"  MSE: {mse:,.0f}\")\n",
    "    print(f\"  RMSE: ${rmse:,.0f}\")\n",
    "    print(f\"  MAE: ${mae:,.0f}\")\n",
    "    print()\n",
    "    \n",
    "    return {'R¬≤': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training\")\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Cross-validation for more robust evaluation\n",
    "print(\"Cross-Validation Results (5-fold):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    model, X_scaled, y, \n",
    "    cv=5, \n",
    "    scoring=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"R¬≤ - Train: {cv_scores['train_r2'].mean():.4f} ¬± {cv_scores['train_r2'].std():.4f}\")\n",
    "print(f\"R¬≤ - Test:  {cv_scores['test_r2'].mean():.4f} ¬± {cv_scores['test_r2'].std():.4f}\")\n",
    "print(f\"RMSE - Train: ${np.sqrt(-cv_scores['train_neg_mean_squared_error']).mean():,.0f} ¬± ${np.sqrt(-cv_scores['train_neg_mean_squared_error']).std():,.0f}\")\n",
    "print(f\"RMSE - Test:  ${np.sqrt(-cv_scores['test_neg_mean_squared_error']).mean():,.0f} ¬± ${np.sqrt(-cv_scores['test_neg_mean_squared_error']).std():,.0f}\")\n",
    "\n",
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted (Training)\n",
    "axes[0, 0].scatter(y_train, y_train_pred, alpha=0.6, color='blue')\n",
    "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Price')\n",
    "axes[0, 0].set_ylabel('Predicted Price')\n",
    "axes[0, 0].set_title(f'Training Set: Actual vs Predicted\\nR¬≤ = {train_metrics[\"R¬≤\"]:.4f}')\n",
    "\n",
    "# 2. Actual vs Predicted (Test)\n",
    "axes[0, 1].scatter(y_test, y_test_pred, alpha=0.6, color='green')\n",
    "axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 1].set_xlabel('Actual Price')\n",
    "axes[0, 1].set_ylabel('Predicted Price')\n",
    "axes[0, 1].set_title(f'Test Set: Actual vs Predicted\\nR¬≤ = {test_metrics[\"R¬≤\"]:.4f}')\n",
    "\n",
    "# 3. Residuals vs Predicted (Training)\n",
    "residuals_train = y_train - y_train_pred\n",
    "axes[1, 0].scatter(y_train_pred, residuals_train, alpha=0.6, color='blue')\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 0].set_xlabel('Predicted Price')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('Training Set: Residual Plot')\n",
    "\n",
    "# 4. Residuals vs Predicted (Test)\n",
    "residuals_test = y_test - y_test_pred\n",
    "axes[1, 1].scatter(y_test_pred, residuals_test, alpha=0.6, color='green')\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Predicted Price')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Test Set: Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': model.coef_,\n",
    "    'Abs_Coefficient': np.abs(model.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (by coefficient magnitude):\")\n",
    "print(\"-\" * 50)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ab7b2",
   "metadata": {},
   "source": [
    "## 7. Overfitting vs Underfitting - The Bias-Variance Tradeoff\n",
    "\n",
    "**Understanding the balance between model complexity and generalization is crucial for building effective ML models.**\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "**Underfitting (High Bias)**:\n",
    "- Model is too simple to capture underlying patterns\n",
    "- Poor performance on both training and test data\n",
    "- High training error, high test error\n",
    "- Signs: Low R¬≤ on both training and validation sets\n",
    "\n",
    "**Overfitting (High Variance)**:\n",
    "- Model memorizes training data instead of learning patterns\n",
    "- Great on training data, poor on new data\n",
    "- Low training error, high test error\n",
    "- Signs: Large gap between training and validation performance\n",
    "\n",
    "**Good Fit (Balanced)**:\n",
    "- Model captures underlying patterns without memorizing noise\n",
    "- Good performance on both training and test data\n",
    "- Training and test errors are similar and acceptably low\n",
    "\n",
    "### The Bias-Variance Tradeoff:\n",
    "- **Bias**: Error from overly simplistic assumptions\n",
    "- **Variance**: Error from sensitivity to small fluctuations in training set\n",
    "- **Goal**: Find the sweet spot that minimizes total error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28539317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Demonstrate overfitting vs underfitting with polynomial features\n",
    "def plot_learning_curves(degrees, X, y):\n",
    "    \"\"\"Plot learning curves for different polynomial degrees\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(degrees), figsize=(5*len(degrees), 4))\n",
    "    if len(degrees) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, degree in enumerate(degrees):\n",
    "        # Create pipeline with polynomial features and scaling\n",
    "        pipe = Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LinearRegression())\n",
    "        ])\n",
    "        \n",
    "        # Calculate learning curves\n",
    "        train_sizes, train_scores, val_scores = learning_curve(\n",
    "            pipe, X, y, cv=5, n_jobs=-1, \n",
    "            train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "            scoring='r2'\n",
    "        )\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        val_mean = np.mean(val_scores, axis=1)\n",
    "        val_std = np.std(val_scores, axis=1)\n",
    "        \n",
    "        # Plot learning curves\n",
    "        axes[idx].plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
    "        axes[idx].fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "        \n",
    "        axes[idx].plot(train_sizes, val_mean, 'o-', color='red', label='Validation Score')\n",
    "        axes[idx].fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "        \n",
    "        axes[idx].set_xlabel('Training Set Size')\n",
    "        axes[idx].set_ylabel('R¬≤ Score')\n",
    "        axes[idx].set_title(f'Learning Curve (Degree {degree})')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Determine fit quality\n",
    "        final_train_score = train_mean[-1]\n",
    "        final_val_score = val_mean[-1]\n",
    "        gap = final_train_score - final_val_score\n",
    "        \n",
    "        if final_val_score < 0.6:\n",
    "            fit_quality = \"Underfitting\"\n",
    "        elif gap > 0.1:\n",
    "            fit_quality = \"Overfitting\"\n",
    "        else:\n",
    "            fit_quality = \"Good Fit\"\n",
    "            \n",
    "        axes[idx].text(0.05, 0.95, f'{fit_quality}\\nGap: {gap:.3f}', \n",
    "                      transform=axes[idx].transAxes, \n",
    "                      verticalalignment='top',\n",
    "                      bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Demonstrate with different polynomial degrees\n",
    "print(\"Demonstrating Bias-Variance Tradeoff with Polynomial Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use single feature for clearer demonstration\n",
    "X_simple = df_clean[['highway-mpg']].copy()\n",
    "y_simple = df_clean['price']\n",
    "\n",
    "# Test different polynomial degrees\n",
    "degrees_to_test = [1, 3, 10]\n",
    "plot_learning_curves(degrees_to_test, X_simple, y_simple)\n",
    "\n",
    "# Show validation curves for model complexity\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Validation curve to find optimal polynomial degree\n",
    "degrees = range(1, 16)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    Pipeline([\n",
    "        ('poly', PolynomialFeatures(include_bias=False)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearRegression())\n",
    "    ]), \n",
    "    X_simple, y_simple, \n",
    "    param_name='poly__degree', \n",
    "    param_range=degrees,\n",
    "    cv=5, scoring='r2'\n",
    ")\n",
    "\n",
    "# Plot validation curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "plt.plot(degrees, train_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.fill_between(degrees, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "\n",
    "plt.plot(degrees, val_mean, 'o-', color='red', label='Validation Score')\n",
    "plt.fill_between(degrees, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "\n",
    "plt.xlabel('Polynomial Degree (Model Complexity)')\n",
    "plt.ylabel('R¬≤ Score')\n",
    "plt.title('Validation Curve: Finding Optimal Model Complexity')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Find optimal degree\n",
    "optimal_idx = np.argmax(val_mean)\n",
    "optimal_degree = degrees[optimal_idx]\n",
    "plt.axvline(x=optimal_degree, color='green', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimal Degree: {optimal_degree}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOptimal polynomial degree: {optimal_degree}\")\n",
    "print(f\"Best validation R¬≤: {val_mean[optimal_idx]:.4f}\")\n",
    "\n",
    "# Practical tips\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRACTICAL TIPS FOR AVOIDING OVERFITTING:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Use cross-validation to get reliable performance estimates\")\n",
    "print(\"2. Monitor the gap between training and validation performance\")\n",
    "print(\"3. Start with simple models and increase complexity gradually\")\n",
    "print(\"4. Use regularization techniques (Ridge, Lasso) for complex models\")\n",
    "print(\"5. Collect more data if possible\")\n",
    "print(\"6. Use feature selection to remove irrelevant features\")\n",
    "print(\"7. Apply early stopping in iterative algorithms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092edc8",
   "metadata": {},
   "source": [
    "## 8. Regularization Techniques - Controlling Model Complexity\n",
    "\n",
    "**Regularization** helps prevent overfitting by adding a penalty term to the loss function, encouraging simpler models.\n",
    "\n",
    "### Types of Regularization:\n",
    "\n",
    "**Ridge Regression (L2 Regularization)**:\n",
    "- Adds penalty proportional to sum of squared coefficients\n",
    "- Shrinks coefficients towards zero but doesn't eliminate them\n",
    "- Good when all features are somewhat relevant\n",
    "- Formula: Loss = MSE + Œ± √ó Œ£(Œ≤¬≤)\n",
    "\n",
    "**Lasso Regression (L1 Regularization)**:\n",
    "- Adds penalty proportional to sum of absolute coefficients\n",
    "- Can drive coefficients to exactly zero (feature selection)\n",
    "- Good for sparse models with few important features\n",
    "- Formula: Loss = MSE + Œ± √ó Œ£|Œ≤|\n",
    "\n",
    "**Elastic Net**:\n",
    "- Combines both L1 and L2 penalties\n",
    "- Balances feature selection and coefficient shrinkage\n",
    "- Formula: Loss = MSE + Œ±‚ÇÅ √ó Œ£|Œ≤| + Œ±‚ÇÇ √ó Œ£(Œ≤¬≤)\n",
    "\n",
    "### Hyperparameter Œ± (alpha):\n",
    "- **Œ± = 0**: No regularization (ordinary least squares)\n",
    "- **Œ± ‚Üí ‚àû**: Maximum regularization (coefficients ‚Üí 0)\n",
    "- **Finding optimal Œ±**: Use cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Prepare high-dimensional data to demonstrate regularization\n",
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "print(f\"Original features: {X.shape[1]}\")\n",
    "print(f\"After polynomial features (degree 3): {X_poly.shape[1]}\")\n",
    "\n",
    "# Split the polynomial data\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the polynomial features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Compare different regularization techniques\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "print(\"Model Comparison with Polynomial Features (degree=3):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    # Count non-zero coefficients\n",
    "    if hasattr(model, 'coef_'):\n",
    "        non_zero_coefs = np.sum(np.abs(model.coef_) > 1e-5)\n",
    "    else:\n",
    "        non_zero_coefs = X_poly.shape[1]\n",
    "    \n",
    "    results[name] = {\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'non_zero_coefs': non_zero_coefs,\n",
    "        'overfitting': train_r2 - test_r2\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Train R¬≤: {train_r2:.4f}, Test R¬≤: {test_r2:.4f}\")\n",
    "    print(f\"  Overfitting Gap: {train_r2 - test_r2:.4f}\")\n",
    "    print(f\"  Test RMSE: ${test_rmse:,.0f}\")\n",
    "    print(f\"  Non-zero coefficients: {non_zero_coefs}/{X_poly.shape[1]}\")\n",
    "    print()\n",
    "\n",
    "# Visualize coefficient comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    if hasattr(model, 'coef_'):\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature_Index': range(len(model.coef_)),\n",
    "            'Coefficient': model.coef_\n",
    "        })\n",
    "        \n",
    "        # Plot coefficient magnitudes\n",
    "        axes[idx].bar(coef_df['Feature_Index'], coef_df['Coefficient'])\n",
    "        axes[idx].set_title(f'{name} - Coefficients')\n",
    "        axes[idx].set_xlabel('Feature Index')\n",
    "        axes[idx].set_ylabel('Coefficient Value')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter tuning for Ridge regression\n",
    "print(\"Hyperparameter Tuning for Ridge Regression:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define alpha values to test\n",
    "alphas = np.logspace(-4, 2, 50)  # From 0.0001 to 100\n",
    "\n",
    "# Grid search for optimal alpha\n",
    "ridge_grid = GridSearchCV(\n",
    "    Ridge(),\n",
    "    param_grid={'alpha': alphas},\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best alpha: {ridge_grid.best_params_['alpha']:.4f}\")\n",
    "print(f\"Best CV score: {ridge_grid.best_score_:.4f}\")\n",
    "\n",
    "# Plot validation curve for Ridge alpha\n",
    "train_scores, val_scores = validation_curve(\n",
    "    Ridge(), X_train_scaled, y_train,\n",
    "    param_name='alpha', param_range=alphas,\n",
    "    cv=5, scoring='r2'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "plt.semilogx(alphas, train_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.fill_between(alphas, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "\n",
    "plt.semilogx(alphas, val_mean, 'o-', color='red', label='Validation Score')\n",
    "plt.fill_between(alphas, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "\n",
    "plt.axvline(x=ridge_grid.best_params_['alpha'], color='green', linestyle='--', \n",
    "           label=f'Optimal Œ± = {ridge_grid.best_params_[\"alpha\"]:.4f}')\n",
    "\n",
    "plt.xlabel('Alpha (Regularization Strength)')\n",
    "plt.ylabel('R¬≤ Score')\n",
    "plt.title('Ridge Regression: Validation Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Test the optimized model\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "y_test_pred_ridge = best_ridge.predict(X_test_scaled)\n",
    "test_r2_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "test_rmse_ridge = np.sqrt(mean_squared_error(y_test, y_test_pred_ridge))\n",
    "\n",
    "print(f\"\\nOptimized Ridge Regression Performance:\")\n",
    "print(f\"Test R¬≤: {test_r2_ridge:.4f}\")\n",
    "print(f\"Test RMSE: ${test_rmse_ridge:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ed85e",
   "metadata": {},
   "source": [
    "## 9. Building Complete ML Pipelines\n",
    "\n",
    "**Pipelines** allow you to chain multiple processing steps together, ensuring consistent data transformations and making your code more maintainable and reproducible.\n",
    "\n",
    "### Benefits of Pipelines:\n",
    "- **Consistency**: Same transformations applied to training and test data\n",
    "- **Reproducibility**: Easy to recreate exact preprocessing steps\n",
    "- **Cross-validation friendly**: Prevents data leakage during CV\n",
    "- **Deployment ready**: Single object contains entire workflow\n",
    "- **Hyperparameter tuning**: Tune preprocessing and model parameters together\n",
    "\n",
    "### Pipeline Components:\n",
    "1. **Data preprocessing**: Scaling, encoding, feature engineering\n",
    "2. **Feature selection**: Remove irrelevant features\n",
    "3. **Model training**: The actual machine learning algorithm\n",
    "4. **Hyperparameter optimization**: Find best parameters via cross-validation\n",
    "\n",
    "### Best Practices:\n",
    "- Always fit transformers on training data only\n",
    "- Use pipelines for cross-validation to prevent data leakage\n",
    "- Include all preprocessing steps in the pipeline\n",
    "- Save the entire pipeline for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import joblib\n",
    "\n",
    "# Define our features\n",
    "numeric_features = ['highway-mpg', 'engine-size', 'horsepower', 'curb-weight']\n",
    "X = df_clean[numeric_features].copy()\n",
    "y = df_clean['price']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Building Complete ML Pipeline\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create comprehensive pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('numeric', Pipeline([\n",
    "            ('poly', PolynomialFeatures(include_bias=False)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('selector', SelectKBest(score_func=f_regression))\n",
    "        ]), numeric_features)\n",
    "    ])),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for comprehensive tuning\n",
    "param_grid = {\n",
    "    'preprocessor__numeric__poly__degree': [1, 2, 3],\n",
    "    'preprocessor__numeric__selector__k': [5, 10, 15, 20],\n",
    "    'regressor__alpha': np.logspace(-4, 2, 10)\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter Grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Perform randomized search (faster than grid search)\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Try 50 random combinations\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nPerforming hyperparameter optimization...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest CV R¬≤ Score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "best_pipeline = random_search.best_estimator_\n",
    "y_test_pred = best_pipeline.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"R¬≤ Score: {test_r2:.4f}\")\n",
    "print(f\"RMSE: ${test_rmse:,.0f}\")\n",
    "\n",
    "# Analyze the best pipeline\n",
    "print(f\"\\nPipeline Analysis:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Get polynomial degree used\n",
    "poly_degree = random_search.best_params_['preprocessor__numeric__poly__degree']\n",
    "print(f\"Polynomial degree: {poly_degree}\")\n",
    "\n",
    "# Get number of features selected\n",
    "k_features = random_search.best_params_['preprocessor__numeric__selector__k']\n",
    "print(f\"Features selected: {k_features}\")\n",
    "\n",
    "# Get regularization strength\n",
    "alpha = random_search.best_params_['regressor__alpha']\n",
    "print(f\"Regularization strength (Œ±): {alpha:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0, 0].scatter(y_test, y_test_pred, alpha=0.6)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Price')\n",
    "axes[0, 0].set_ylabel('Predicted Price')\n",
    "axes[0, 0].set_title(f'Optimized Pipeline: Actual vs Predicted\\nR¬≤ = {test_r2:.4f}')\n",
    "\n",
    "# 2. Residuals\n",
    "residuals = y_test - y_test_pred\n",
    "axes[0, 1].scatter(y_test_pred, residuals, alpha=0.6)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 1].set_xlabel('Predicted Price')\n",
    "axes[0, 1].set_ylabel('Residuals')\n",
    "axes[0, 1].set_title('Residual Plot')\n",
    "\n",
    "# 3. Feature importance (coefficients)\n",
    "# Get transformed feature names\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_temp = poly_features.fit_transform(X_train)\n",
    "feature_names = poly_features.get_feature_names_out(numeric_features)\n",
    "\n",
    "# Get selected features\n",
    "selector = best_pipeline.named_steps['preprocessor'].named_transformers_['numeric'].named_steps['selector']\n",
    "selected_features = selector.get_support()\n",
    "selected_feature_names = [feature_names[i] for i in range(len(feature_names)) if selected_features[i]]\n",
    "\n",
    "# Get coefficients\n",
    "coef = best_pipeline.named_steps['regressor'].coef_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_feature_names,\n",
    "    'Coefficient': coef,\n",
    "    'Abs_Coefficient': np.abs(coef)\n",
    "}).sort_values('Abs_Coefficient', ascending=True)\n",
    "\n",
    "# Plot top 10 features\n",
    "top_features = feature_importance.tail(10)\n",
    "axes[1, 0].barh(range(len(top_features)), top_features['Coefficient'])\n",
    "axes[1, 0].set_yticks(range(len(top_features)))\n",
    "axes[1, 0].set_yticklabels(top_features['Feature'])\n",
    "axes[1, 0].set_xlabel('Coefficient Value')\n",
    "axes[1, 0].set_title('Top 10 Feature Importance')\n",
    "\n",
    "# 4. Cross-validation scores distribution\n",
    "cv_scores = random_search.cv_results_['mean_test_score']\n",
    "axes[1, 1].hist(cv_scores, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].axvline(random_search.best_score_, color='red', linestyle='--', \n",
    "                  label=f'Best Score: {random_search.best_score_:.4f}')\n",
    "axes[1, 1].set_xlabel('CV R¬≤ Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of CV Scores')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the pipeline\n",
    "pipeline_filename = 'optimized_car_price_pipeline.joblib'\n",
    "joblib.dump(best_pipeline, pipeline_filename)\n",
    "print(f\"\\nPipeline saved as: {pipeline_filename}\")\n",
    "\n",
    "# Demonstrate pipeline usage for new predictions\n",
    "print(f\"\\nPipeline Usage Example:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create sample new data\n",
    "new_car_data = pd.DataFrame({\n",
    "    'highway-mpg': [30, 25, 35],\n",
    "    'engine-size': [2.0, 3.5, 1.8],\n",
    "    'horsepower': [150, 250, 120],\n",
    "    'curb-weight': [2500, 3500, 2200]\n",
    "})\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_pipeline.predict(new_car_data)\n",
    "\n",
    "print(\"New car predictions:\")\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Car {i+1}: ${pred:,.0f}\")\n",
    "    \n",
    "# Show the complete pipeline structure\n",
    "print(f\"\\nPipeline Structure:\")\n",
    "print(\"-\" * 20)\n",
    "print(best_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4872531",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices\n",
    "\n",
    "### Key Takeaways from Model Development\n",
    "\n",
    "**üéØ Model Development Process:**\n",
    "1. **Start Simple**: Begin with basic linear regression to establish baseline\n",
    "2. **Add Complexity Gradually**: Introduce polynomial features, multiple variables step by step\n",
    "3. **Validate Continuously**: Use cross-validation to monitor generalization performance\n",
    "4. **Regularize When Needed**: Apply Ridge/Lasso to prevent overfitting with complex models\n",
    "5. **Optimize Systematically**: Use grid/random search for hyperparameter tuning\n",
    "6. **Build Pipelines**: Create reproducible, deployment-ready workflows\n",
    "\n",
    "**üìä Evaluation Best Practices:**\n",
    "- **Multiple Metrics**: Don't rely on R¬≤ alone - consider RMSE, MAE for interpretability\n",
    "- **Cross-Validation**: Use 5-fold CV for reliable performance estimates\n",
    "- **Learning Curves**: Monitor training vs validation performance to detect overfitting\n",
    "- **Residual Analysis**: Check for patterns in residuals that indicate model issues\n",
    "- **Feature Importance**: Understand which features drive predictions\n",
    "\n",
    "**‚öñÔ∏è Bias-Variance Tradeoff:**\n",
    "- **Underfitting**: Model too simple ‚Üí Add complexity (polynomial features, more variables)\n",
    "- **Overfitting**: Model too complex ‚Üí Add regularization, reduce features, get more data\n",
    "- **Sweet Spot**: Good performance on both training and test sets with minimal gap\n",
    "\n",
    "**üîß Regularization Guidelines:**\n",
    "- **Ridge**: Use when all features are somewhat relevant\n",
    "- **Lasso**: Use for feature selection and sparse models\n",
    "- **ElasticNet**: Use when you want both shrinkage and selection\n",
    "- **Œ± tuning**: Always use cross-validation to find optimal regularization strength\n",
    "\n",
    "**üöÄ Pipeline Advantages:**\n",
    "- **Prevents Data Leakage**: Transformations applied consistently\n",
    "- **Reproducible**: Entire workflow captured in single object\n",
    "- **Deployment Ready**: Easy to save and load for production\n",
    "- **Hyperparameter Tuning**: Optimize preprocessing and model together\n",
    "\n",
    "### Real-World Application Tips\n",
    "\n",
    "**Data Quality:**\n",
    "- Clean data is more important than complex algorithms\n",
    "- Handle missing values appropriately\n",
    "- Remove or investigate outliers\n",
    "- Ensure features are relevant and informative\n",
    "\n",
    "**Feature Engineering:**\n",
    "- Domain knowledge is crucial for creating meaningful features\n",
    "- Polynomial features can capture non-linear relationships\n",
    "- Feature scaling is essential for many algorithms\n",
    "- Consider interaction terms between features\n",
    "\n",
    "**Model Selection:**\n",
    "- Start with interpretable models (linear regression)\n",
    "- Add complexity only if it improves validation performance\n",
    "- Consider computational requirements for production\n",
    "- Balance accuracy with interpretability needs\n",
    "\n",
    "**Validation Strategy:**\n",
    "- Always keep a separate test set untouched until final evaluation\n",
    "- Use time-based splits for time series data\n",
    "- Ensure train/validation/test splits are representative\n",
    "- Monitor performance over time in production\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "‚ùå **Data Leakage**: Using future information or test set for preprocessing\n",
    "‚ùå **Overfitting to Validation Set**: Excessive hyperparameter tuning on same validation set\n",
    "‚ùå **Ignoring Business Context**: Building accurate but unusable models\n",
    "‚ùå **Feature Scaling Mistakes**: Not scaling consistently across train/test sets\n",
    "‚ùå **Poor Evaluation**: Relying only on training performance or single metrics\n",
    "\n",
    "### Next Steps in Your ML Journey\n",
    "\n",
    "1. **Advanced Algorithms**: Explore tree-based methods (Random Forest, XGBoost)\n",
    "2. **Feature Selection**: Learn automated feature selection techniques\n",
    "3. **Ensemble Methods**: Combine multiple models for better performance\n",
    "4. **Time Series**: Apply these concepts to temporal data\n",
    "5. **Deep Learning**: Understand neural networks for complex patterns\n",
    "6. **MLOps**: Learn deployment, monitoring, and maintenance of ML systems\n",
    "\n",
    "**Remember**: *The goal is not just to build models, but to solve real problems with reliable, maintainable, and interpretable solutions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa79df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81481a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
