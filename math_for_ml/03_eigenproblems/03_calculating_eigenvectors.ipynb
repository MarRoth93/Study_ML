{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49931273",
   "metadata": {},
   "source": [
    "# Calculating Eigenvectors: From Geometry to Algebra\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "Now that we understand eigenvectors **geometrically**, it's time to learn how to **calculate them algebraically**. In this notebook, we'll:\n",
    "\n",
    "1. **Formalize the eigenvalue equation** mathematically\n",
    "2. **Derive the characteristic polynomial** method\n",
    "3. **Work through step-by-step calculations** for 2√ó2 matrices\n",
    "4. **Validate our results** with known examples\n",
    "5. **Understand why computers are essential** for larger problems\n",
    "\n",
    "## üßÆ From Intuition to Calculation\n",
    "\n",
    "We've seen that eigenvectors are special vectors that maintain their direction under transformation. Now we need a systematic way to **find them** when they exist.\n",
    "\n",
    "### The Central Question\n",
    "Given a transformation matrix $A$, how do we find vectors $\\mathbf{x}$ such that:\n",
    "> **\"Applying the transformation is the same as just scaling the vector\"**\n",
    "\n",
    "Let's turn this geometric insight into precise mathematics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e34259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üìö Ready to explore eigenvalue calculations!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "from sympy import symbols, Matrix, solve, expand, simplify\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Enable pretty printing for symbolic math\n",
    "sp.init_printing()\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìö Ready to explore eigenvalue calculations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82465f7",
   "metadata": {},
   "source": [
    "## Step 1: The Fundamental Eigenvalue Equation\n",
    "\n",
    "### From Geometry to Algebra\n",
    "\n",
    "We know that eigenvectors **maintain their direction** after transformation. Mathematically, this means:\n",
    "\n",
    "> **\"Applying transformation $A$ to eigenvector $\\mathbf{x}$ is the same as scaling $\\mathbf{x}$ by some factor $\\lambda$\"**\n",
    "\n",
    "This gives us the **fundamental eigenvalue equation**:\n",
    "\n",
    "$$A\\mathbf{x} = \\lambda\\mathbf{x}$$\n",
    "\n",
    "Where:\n",
    "- $A$ is our $n \\times n$ transformation matrix\n",
    "- $\\mathbf{x}$ is the eigenvector (what we want to find)\n",
    "- $\\lambda$ is the eigenvalue (the scaling factor)\n",
    "\n",
    "### Visual Interpretation\n",
    "\n",
    "```\n",
    "Original vector:    x‚Éó\n",
    "Apply matrix A:     Ax‚Éó  \n",
    "Scale by Œª:         Œªx‚Éó\n",
    "\n",
    "For eigenvectors:   Ax‚Éó = Œªx‚Éó\n",
    "```\n",
    "\n",
    "The left side transforms the vector, the right side just scales it. When these are equal, we've found an eigenvector!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cf460",
   "metadata": {},
   "source": [
    "## Step 2: Rearranging the Equation\n",
    "\n",
    "### Moving Everything to One Side\n",
    "\n",
    "Starting with: $A\\mathbf{x} = \\lambda\\mathbf{x}$\n",
    "\n",
    "Let's move everything to the left side:\n",
    "$$A\\mathbf{x} - \\lambda\\mathbf{x} = \\mathbf{0}$$\n",
    "\n",
    "### The Identity Matrix Trick\n",
    "\n",
    "There's a problem: we can't subtract a scalar $\\lambda$ from a matrix $A$ directly! \n",
    "\n",
    "**Solution**: Use the identity matrix $I$\n",
    "$$A\\mathbf{x} - \\lambda I\\mathbf{x} = \\mathbf{0}$$\n",
    "\n",
    "Now we can factor out $\\mathbf{x}$:\n",
    "$$(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$$\n",
    "\n",
    "### Why the Identity Matrix Works\n",
    "\n",
    "The identity matrix $I$ is:\n",
    "$$I = \\begin{bmatrix} 1 & 0 & \\cdots & 0 \\\\ 0 & 1 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 1 \\end{bmatrix}$$\n",
    "\n",
    "So $\\lambda I\\mathbf{x} = \\lambda\\mathbf{x}$ (multiplying by $I$ doesn't change the vector).\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "We now have: $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$\n",
    "\n",
    "This means we need $(A - \\lambda I)$ to transform vector $\\mathbf{x}$ into the zero vector!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a41804",
   "metadata": {},
   "source": [
    "## Step 3: The Determinant Condition\n",
    "\n",
    "### Two Possible Solutions\n",
    "\n",
    "From $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$, we have two cases:\n",
    "\n",
    "1. **Trivial solution**: $\\mathbf{x} = \\mathbf{0}$ (the zero vector)\n",
    "2. **Non-trivial solution**: $(A - \\lambda I) = \\mathbf{0}$ (the matrix transforms to zero)\n",
    "\n",
    "### Why We Want Non-Trivial Solutions\n",
    "\n",
    "The **trivial solution** $\\mathbf{x} = \\mathbf{0}$ is useless because:\n",
    "- The zero vector has no direction\n",
    "- It doesn't tell us anything about the transformation\n",
    "\n",
    "We want **non-trivial solutions** where $\\mathbf{x} \\neq \\mathbf{0}$.\n",
    "\n",
    "### The Determinant Test\n",
    "\n",
    "For non-trivial solutions to exist, the matrix $(A - \\lambda I)$ must be **singular** (non-invertible).\n",
    "\n",
    "**Key insight**: A matrix is singular if and only if its determinant is zero!\n",
    "\n",
    "Therefore, we need:\n",
    "$$\\det(A - \\lambda I) = 0$$\n",
    "\n",
    "This equation will give us the **eigenvalues** $\\lambda$. Once we have those, we can find the corresponding **eigenvectors** $\\mathbf{x}$.\n",
    "\n",
    "### The Algorithm\n",
    "\n",
    "1. **Find eigenvalues**: Solve $\\det(A - \\lambda I) = 0$\n",
    "2. **Find eigenvectors**: For each $\\lambda$, solve $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98958a29",
   "metadata": {},
   "source": [
    "## Step 4: The Characteristic Polynomial (2√ó2 Case)\n",
    "\n",
    "### General 2√ó2 Matrix\n",
    "\n",
    "Let's work with a general 2√ó2 transformation matrix:\n",
    "$$A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$$\n",
    "\n",
    "### Computing $A - \\lambda I$\n",
    "\n",
    "$$A - \\lambda I = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} - \\lambda \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} a - \\lambda & b \\\\ c & d - \\lambda \\end{bmatrix}$$\n",
    "\n",
    "### Finding the Determinant\n",
    "\n",
    "$$\\det(A - \\lambda I) = \\det\\begin{bmatrix} a - \\lambda & b \\\\ c & d - \\lambda \\end{bmatrix}$$\n",
    "\n",
    "Using the 2√ó2 determinant formula: $\\det\\begin{bmatrix} p & q \\\\ r & s \\end{bmatrix} = ps - qr$\n",
    "\n",
    "$$\\det(A - \\lambda I) = (a - \\lambda)(d - \\lambda) - bc$$\n",
    "\n",
    "### Expanding to Get the Characteristic Polynomial\n",
    "\n",
    "$$\\det(A - \\lambda I) = ad - a\\lambda - d\\lambda + \\lambda^2 - bc$$\n",
    "$$= \\lambda^2 - (a + d)\\lambda + (ad - bc)$$\n",
    "\n",
    "### The Standard Form\n",
    "\n",
    "$$\\lambda^2 - (a + d)\\lambda + (ad - bc) = 0$$\n",
    "\n",
    "This is called the **characteristic polynomial**. Its roots are the eigenvalues!\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- **Coefficient of $\\lambda$**: $-(a + d)$ is the negative **trace** of $A$\n",
    "- **Constant term**: $(ad - bc)$ is the **determinant** of $A$\n",
    "- For any 2√ó2 matrix, we get a **quadratic equation** in $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45bea0",
   "metadata": {},
   "source": [
    "## Example 1: Vertical Scaling by Factor 2\n",
    "\n",
    "Let's apply our method to a transformation we already understand geometrically!\n",
    "\n",
    "### The Matrix\n",
    "$$A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix}$$\n",
    "\n",
    "This matrix:\n",
    "- Keeps x-coordinates unchanged: $x' = x$\n",
    "- Doubles y-coordinates: $y' = 2y$\n",
    "\n",
    "### Step-by-Step Calculation\n",
    "\n",
    "We expect eigenvectors along the x-axis (Œª=1) and y-axis (Œª=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d0092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Example 1: Vertical Scaling by Factor 2\n",
      "==================================================\n",
      "Matrix A = \n",
      "‚é°1  0‚é§\n",
      "‚é¢    ‚é•\n",
      "‚é£0  2‚é¶\n",
      "\n",
      "A - ŒªI = \n",
      "‚é°1 - Œª    0  ‚é§\n",
      "‚é¢            ‚é•\n",
      "‚é£  0    2 - Œª‚é¶\n",
      "\n",
      "det(A - ŒªI) = lambda**2 - 3*lambda + 2\n",
      "Expanded: lambda**2 - 3*lambda + 2\n",
      "\n",
      "Eigenvalues: Œª = [1, 2]\n",
      "\n",
      "üéØ Analysis:\n",
      "‚Ä¢ Œª‚ÇÅ = 1 (corresponds to horizontal direction)\n",
      "‚Ä¢ Œª‚ÇÇ = 2 (corresponds to vertical direction)\n",
      "\n",
      "‚úÖ NumPy verification:\n",
      "Eigenvalues: [1. 2.]\n",
      "Eigenvectors:\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Vertical Scaling Matrix\n",
    "print(\"üîç Example 1: Vertical Scaling by Factor 2\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define the matrix symbolically for exact calculations\n",
    "a, b, c, d = 1, 0, 0, 2\n",
    "A_symbolic = Matrix([[a, b], [c, d]])\n",
    "print(f\"Matrix A = \")\n",
    "sp.pprint(A_symbolic)\n",
    "\n",
    "# Define lambda as a symbol\n",
    "lam = symbols('lambda')\n",
    "\n",
    "# Compute A - lambda*I\n",
    "I = Matrix([[1, 0], [0, 1]])\n",
    "A_minus_lamI = A_symbolic - lam * I\n",
    "\n",
    "print(f\"\\nA - ŒªI = \")\n",
    "sp.pprint(A_minus_lamI)\n",
    "\n",
    "# Compute the determinant\n",
    "det_expr = A_minus_lamI.det()\n",
    "print(f\"\\ndet(A - ŒªI) = {det_expr}\")\n",
    "\n",
    "# Expand the determinant\n",
    "expanded_det = expand(det_expr)\n",
    "print(f\"Expanded: {expanded_det}\")\n",
    "\n",
    "# Solve for eigenvalues\n",
    "eigenvalues = solve(expanded_det, lam)\n",
    "print(f\"\\nEigenvalues: Œª = {eigenvalues}\")\n",
    "\n",
    "print(\"\\nüéØ Analysis:\")\n",
    "print(f\"‚Ä¢ Œª‚ÇÅ = {eigenvalues[0]} (corresponds to horizontal direction)\")\n",
    "print(f\"‚Ä¢ Œª‚ÇÇ = {eigenvalues[1]} (corresponds to vertical direction)\")\n",
    "\n",
    "# Let's verify with NumPy\n",
    "A_numeric = np.array([[1, 0], [0, 2]])\n",
    "eigenvals_numpy, eigenvecs_numpy = np.linalg.eig(A_numeric)\n",
    "print(f\"\\n‚úÖ NumPy verification:\")\n",
    "print(f\"Eigenvalues: {eigenvals_numpy}\")\n",
    "print(f\"Eigenvectors:\\n{eigenvecs_numpy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edf6aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç Finding Eigenvectors for Each Eigenvalue\n",
      "============================================================\n",
      "\n",
      "üìå Case 1: Œª = 1\n",
      "--------------------\n",
      "(A - ŒªI) = \n",
      "‚é°0  0‚é§\n",
      "‚é¢    ‚é•\n",
      "‚é£0  1‚é¶\n",
      "\n",
      "(A - ŒªI)x = \n",
      "‚é°0 ‚é§\n",
      "‚é¢  ‚é•\n",
      "‚é£x‚ÇÇ‚é¶\n",
      "= [0, 0]\n",
      "\n",
      "System of equations:\n",
      "0 √ó x‚ÇÅ + 0 √ó x‚ÇÇ = 0  ‚Üí  0 = 0 (always true)\n",
      "0 √ó x‚ÇÅ + 1 √ó x‚ÇÇ = 0  ‚Üí  x‚ÇÇ = 0\n",
      "\n",
      "üí° Solution: x‚ÇÇ must be 0, but x‚ÇÅ can be anything!\n",
      "Eigenvector: [t, 0] where t is any non-zero number\n",
      "Standard form: [1, 0] (horizontal direction)\n",
      "\n",
      "üìå Case 2: Œª = 2\n",
      "--------------------\n",
      "(A - ŒªI) = \n",
      "‚é°-1  0‚é§\n",
      "‚é¢     ‚é•\n",
      "‚é£0   0‚é¶\n",
      "\n",
      "(A - ŒªI)x = \n",
      "‚é°-x‚ÇÅ‚é§\n",
      "‚é¢   ‚é•\n",
      "‚é£ 0 ‚é¶\n",
      "= [0, 0]\n",
      "\n",
      "System of equations:\n",
      "-1 √ó x‚ÇÅ + 0 √ó x‚ÇÇ = 0  ‚Üí  x‚ÇÅ = 0\n",
      " 0 √ó x‚ÇÅ + 0 √ó x‚ÇÇ = 0  ‚Üí  0 = 0 (always true)\n",
      "\n",
      "üí° Solution: x‚ÇÅ must be 0, but x‚ÇÇ can be anything!\n",
      "Eigenvector: [0, t] where t is any non-zero number\n",
      "Standard form: [0, 1] (vertical direction)\n",
      "\n",
      "üéØ Final Results:\n",
      "‚Ä¢ Eigenvalue Œª‚ÇÅ = 1, Eigenvector = [1, 0] (horizontal)\n",
      "‚Ä¢ Eigenvalue Œª‚ÇÇ = 2, Eigenvector = [0, 1] (vertical)\n",
      "\n",
      "‚úÖ This matches our geometric intuition!\n"
     ]
    }
   ],
   "source": [
    "# Now let's find the eigenvectors step by step\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç Finding Eigenvectors for Each Eigenvalue\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define symbolic variables for the eigenvector components\n",
    "x1, x2 = symbols('x1 x2')\n",
    "x_vec = Matrix([x1, x2])\n",
    "\n",
    "# For Œª = 1\n",
    "print(\"\\nüìå Case 1: Œª = 1\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "lambda1 = 1\n",
    "A_minus_lambda1_I = A_symbolic - lambda1 * I\n",
    "print(\"(A - ŒªI) = \")\n",
    "sp.pprint(A_minus_lambda1_I)\n",
    "\n",
    "# Solve (A - ŒªI)x = 0\n",
    "equation1 = A_minus_lambda1_I * x_vec\n",
    "print(f\"\\n(A - ŒªI)x = \")\n",
    "sp.pprint(equation1)\n",
    "print(\"= [0, 0]\")\n",
    "\n",
    "# This gives us the system of equations\n",
    "print(\"\\nSystem of equations:\")\n",
    "print(\"0 √ó x‚ÇÅ + 0 √ó x‚ÇÇ = 0  ‚Üí  0 = 0 (always true)\")\n",
    "print(\"0 √ó x‚ÇÅ + 1 √ó x‚ÇÇ = 0  ‚Üí  x‚ÇÇ = 0\")\n",
    "\n",
    "print(\"\\nüí° Solution: x‚ÇÇ must be 0, but x‚ÇÅ can be anything!\")\n",
    "print(\"Eigenvector: [t, 0] where t is any non-zero number\")\n",
    "print(\"Standard form: [1, 0] (horizontal direction)\")\n",
    "\n",
    "# For Œª = 2  \n",
    "print(\"\\nüìå Case 2: Œª = 2\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "lambda2 = 2\n",
    "A_minus_lambda2_I = A_symbolic - lambda2 * I\n",
    "print(\"(A - ŒªI) = \")\n",
    "sp.pprint(A_minus_lambda2_I)\n",
    "\n",
    "equation2 = A_minus_lambda2_I * x_vec\n",
    "print(f\"\\n(A - ŒªI)x = \")\n",
    "sp.pprint(equation2)\n",
    "print(\"= [0, 0]\")\n",
    "\n",
    "print(\"\\nSystem of equations:\")\n",
    "print(\"-1 √ó x‚ÇÅ + 0 √ó x‚ÇÇ = 0  ‚Üí  x‚ÇÅ = 0\")\n",
    "print(\" 0 √ó x‚ÇÅ + 0 √ó x‚ÇÇ = 0  ‚Üí  0 = 0 (always true)\")\n",
    "\n",
    "print(\"\\nüí° Solution: x‚ÇÅ must be 0, but x‚ÇÇ can be anything!\")\n",
    "print(\"Eigenvector: [0, t] where t is any non-zero number\")\n",
    "print(\"Standard form: [0, 1] (vertical direction)\")\n",
    "\n",
    "print(\"\\nüéØ Final Results:\")\n",
    "print(\"‚Ä¢ Eigenvalue Œª‚ÇÅ = 1, Eigenvector = [1, 0] (horizontal)\")\n",
    "print(\"‚Ä¢ Eigenvalue Œª‚ÇÇ = 2, Eigenvector = [0, 1] (vertical)\")\n",
    "print(\"\\n‚úÖ This matches our geometric intuition!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310dd9fc",
   "metadata": {},
   "source": [
    "## Example 2: 90¬∞ Rotation (No Real Eigenvectors)\n",
    "\n",
    "Now let's verify that a 90¬∞ rotation has **no real eigenvectors**, as we expect from our geometric understanding.\n",
    "\n",
    "### The Matrix\n",
    "$$A = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}$$\n",
    "\n",
    "This matrix rotates vectors 90¬∞ counterclockwise:\n",
    "- $(1,0) \\rightarrow (0,1)$\n",
    "- $(0,1) \\rightarrow (-1,0)$\n",
    "\n",
    "Since all vectors change direction, we expect **no real eigenvectors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9625e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Example 2: 90¬∞ Counterclockwise Rotation\n",
      "==================================================\n",
      "Matrix A = \n",
      "‚é°0  -1‚é§\n",
      "‚é¢     ‚é•\n",
      "‚é£1  0 ‚é¶\n",
      "\n",
      "A - ŒªI = \n",
      "‚é°-Œª  -1‚é§\n",
      "‚é¢      ‚é•\n",
      "‚é£1   -Œª‚é¶\n",
      "\n",
      "det(A - ŒªI) = lambda**2 + 1\n",
      "Expanded: lambda**2 + 1\n",
      "\n",
      "Eigenvalues: Œª = [-I, I]\n",
      "\n",
      "üéØ Analysis:\n",
      "The characteristic polynomial is: Œª¬≤ + 1 = 0\n",
      "This gives: Œª¬≤ = -1\n",
      "Solutions: Œª = ¬±i (complex numbers!)\n",
      "\n",
      "‚ùå No real eigenvalues means no real eigenvectors!\n",
      "This confirms our geometric intuition: rotation changes all vector directions.\n",
      "\n",
      "‚úÖ NumPy verification:\n",
      "Eigenvalues: [0.+1.j 0.-1.j]\n",
      "(Complex eigenvalues as expected)\n",
      "\n",
      "üß™ Testing vector transformations:\n",
      "[1, 0] ‚Üí [0, 1]\n",
      "[0, 1] ‚Üí [-1, 0]\n",
      "[1, 1] ‚Üí [-1, 1]\n",
      "\n",
      "üí° Every vector changes direction - no eigenvectors exist!\n"
     ]
    }
   ],
   "source": [
    "# Example 2: 90¬∞ Rotation Matrix\n",
    "print(\"üîÑ Example 2: 90¬∞ Counterclockwise Rotation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define the 90¬∞ rotation matrix\n",
    "A_rotation = Matrix([[0, -1], [1, 0]])\n",
    "print(\"Matrix A = \")\n",
    "sp.pprint(A_rotation)\n",
    "\n",
    "# Compute A - lambda*I\n",
    "A_rot_minus_lamI = A_rotation - lam * I\n",
    "print(f\"\\nA - ŒªI = \")\n",
    "sp.pprint(A_rot_minus_lamI)\n",
    "\n",
    "# Compute the determinant\n",
    "det_rotation = A_rot_minus_lamI.det()\n",
    "print(f\"\\ndet(A - ŒªI) = {det_rotation}\")\n",
    "\n",
    "# Expand \n",
    "expanded_det_rot = expand(det_rotation)\n",
    "print(f\"Expanded: {expanded_det_rot}\")\n",
    "\n",
    "# Solve for eigenvalues\n",
    "eigenvalues_rot = solve(expanded_det_rot, lam)\n",
    "print(f\"\\nEigenvalues: Œª = {eigenvalues_rot}\")\n",
    "\n",
    "print(\"\\nüéØ Analysis:\")\n",
    "print(\"The characteristic polynomial is: Œª¬≤ + 1 = 0\")\n",
    "print(\"This gives: Œª¬≤ = -1\")\n",
    "print(\"Solutions: Œª = ¬±i (complex numbers!)\")\n",
    "\n",
    "print(\"\\n‚ùå No real eigenvalues means no real eigenvectors!\")\n",
    "print(\"This confirms our geometric intuition: rotation changes all vector directions.\")\n",
    "\n",
    "# Verify with NumPy\n",
    "A_rot_numeric = np.array([[0, -1], [1, 0]])\n",
    "eigenvals_rot_numpy, eigenvecs_rot_numpy = np.linalg.eig(A_rot_numeric)\n",
    "print(f\"\\n‚úÖ NumPy verification:\")\n",
    "print(f\"Eigenvalues: {eigenvals_rot_numpy}\")\n",
    "print(\"(Complex eigenvalues as expected)\")\n",
    "\n",
    "# Let's see what happens to some test vectors\n",
    "test_vectors = np.array([[1, 0], [0, 1], [1, 1]]).T\n",
    "transformed = A_rot_numeric @ test_vectors\n",
    "\n",
    "print(f\"\\nüß™ Testing vector transformations:\")\n",
    "for i in range(test_vectors.shape[1]):\n",
    "    original = test_vectors[:, i]\n",
    "    new = transformed[:, i]\n",
    "    print(f\"[{original[0]}, {original[1]}] ‚Üí [{new[0]}, {new[1]}]\")\n",
    "    \n",
    "print(\"\\nüí° Every vector changes direction - no eigenvectors exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398e52a",
   "metadata": {},
   "source": [
    "## Why Computers Are Essential for Eigenproblems\n",
    "\n",
    "### The Complexity Problem\n",
    "\n",
    "While we can solve 2√ó2 matrices by hand, **real-world problems** involve much larger matrices:\n",
    "\n",
    "- **Machine Learning**: 100s to 1000s of dimensions\n",
    "- **Image Processing**: Millions of pixels  \n",
    "- **Scientific Computing**: Massive simulation grids\n",
    "\n",
    "### The Polynomial Degree Problem\n",
    "\n",
    "For an $n \\times n$ matrix, the characteristic polynomial has **degree $n$**:\n",
    "\n",
    "- **2√ó2 matrix**: Quadratic equation (solvable with formula)\n",
    "- **3√ó3 matrix**: Cubic equation (harder, but possible)\n",
    "- **4√ó4 matrix**: Quartic equation (very difficult)\n",
    "- **5√ó5+ matrix**: **No general analytical solution exists!**\n",
    "\n",
    "### Beyond Analytical Methods\n",
    "\n",
    "For $n \\geq 5$, we **cannot** solve the characteristic polynomial analytically. We need:\n",
    "\n",
    "1. **Iterative numerical methods**\n",
    "2. **Approximation algorithms**\n",
    "3. **Specialized eigenvalue solvers**\n",
    "\n",
    "### What Computers Use\n",
    "\n",
    "Modern eigenvalue algorithms include:\n",
    "- **QR Algorithm**: Most common general-purpose method\n",
    "- **Power Method**: For finding largest eigenvalue\n",
    "- **Arnoldi Method**: For sparse matrices\n",
    "- **Jacobi Method**: For symmetric matrices\n",
    "\n",
    "### The Takeaway\n",
    "\n",
    "**Understanding concepts > Manual calculation**\n",
    "\n",
    "Focus on:\n",
    "‚úÖ **Geometric intuition** of what eigenvectors mean  \n",
    "‚úÖ **When eigenproblems arise** in applications  \n",
    "‚úÖ **Interpreting results** from computational tools  \n",
    "\n",
    "‚ùå **Hand calculations** for large matrices  \n",
    "‚ùå **Memorizing formulas** for higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca9581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Complexity of Higher-Dimensional Eigenproblems\n",
    "import time\n",
    "\n",
    "def demonstrate_complexity():\n",
    "    print(\"üñ•Ô∏è  Computational Complexity Demonstration\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test different matrix sizes\n",
    "    sizes = [10, 50, 100, 200, 500]\n",
    "    \n",
    "    print(\"Matrix Size | Time (seconds) | Characteristic Polynomial Degree\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for n in sizes:\n",
    "        # Create a random matrix\n",
    "        np.random.seed(42)  # For reproducible results\n",
    "        A = np.random.randn(n, n)\n",
    "        \n",
    "        # Time the eigenvalue computation\n",
    "        start_time = time.time()\n",
    "        eigenvals, eigenvecs = np.linalg.eig(A)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        computation_time = end_time - start_time\n",
    "        \n",
    "        print(f\"    {n:3d}     |    {computation_time:.4f}     |              {n}\")\n",
    "    \n",
    "    print(\"\\nüí° Key Observations:\")\n",
    "    print(\"‚Ä¢ Computation time grows rapidly with matrix size\")\n",
    "    print(\"‚Ä¢ For n=500, we'd need to solve a 500th-degree polynomial!\")\n",
    "    print(\"‚Ä¢ NumPy uses sophisticated numerical algorithms, not polynomial solving\")\n",
    "\n",
    "demonstrate_complexity()\n",
    "\n",
    "# Let's see what a 3x3 characteristic polynomial looks like\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç What a 3√ó3 Characteristic Polynomial Looks Like\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a simple 3x3 matrix\n",
    "A_3x3 = Matrix([[1, 2, 0], [0, 3, 1], [0, 0, 2]])\n",
    "print(\"3√ó3 Matrix:\")\n",
    "sp.pprint(A_3x3)\n",
    "\n",
    "# Compute characteristic polynomial\n",
    "I_3x3 = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "char_poly_3x3 = (A_3x3 - lam * I_3x3).det()\n",
    "expanded_char_poly = expand(char_poly_3x3)\n",
    "\n",
    "print(f\"\\nCharacteristic polynomial:\")\n",
    "print(f\"det(A - ŒªI) = {expanded_char_poly}\")\n",
    "\n",
    "eigenvals_3x3 = solve(expanded_char_poly, lam)\n",
    "print(f\"\\nEigenvalues: {eigenvals_3x3}\")\n",
    "\n",
    "print(\"\\nüéØ Even for 3√ó3, the polynomial is getting complex!\")\n",
    "print(\"   Imagine what a 100√ó100 matrix would look like...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Interactive Practice: Calculate Eigenvalues Yourself!\n",
    "\n",
    "def eigenvalue_practice():\n",
    "    \"\"\"\n",
    "    Practice calculating eigenvalues for simple 2x2 matrices\n",
    "    \"\"\"\n",
    "    print(\"üß™ Practice Exercise: Calculate Eigenvalues Step by Step\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Practice matrices\n",
    "    practice_matrices = [\n",
    "        {\n",
    "            'name': 'Horizontal Scaling',\n",
    "            'matrix': np.array([[3, 0], [0, 1]]),\n",
    "            'hint': 'This scales x by 3, y by 1'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Diagonal Matrix',\n",
    "            'matrix': np.array([[2, 0], [0, -1]]),\n",
    "            'hint': 'Diagonal matrices have eigenvalues on the diagonal!'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Simple Shear',\n",
    "            'matrix': np.array([[1, 1], [0, 1]]),\n",
    "            'hint': 'This is a shear transformation'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, problem in enumerate(practice_matrices, 1):\n",
    "        print(f\"\\nüìù Problem {i}: {problem['name']}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(\"Matrix:\")\n",
    "        print(problem['matrix'])\n",
    "        print(f\"Hint: {problem['hint']}\")\n",
    "        \n",
    "        print(\"\\nü§î Try to answer these questions:\")\n",
    "        print(\"1. What is the characteristic polynomial?\")\n",
    "        print(\"2. What are the eigenvalues?\")\n",
    "        print(\"3. Can you predict the eigenvectors?\")\n",
    "        \n",
    "        print(\"\\nüí° Manual calculation steps:\")\n",
    "        a, b, c, d = problem['matrix'].flatten()\n",
    "        print(f\"   A = [[{a}, {b}], [{c}, {d}]]\")\n",
    "        print(f\"   Characteristic polynomial: Œª¬≤ - ({a}+{d})Œª + ({a*d}-{b*c}) = 0\")\n",
    "        print(f\"   Simplified: Œª¬≤ - {a+d}Œª + {a*d-b*c} = 0\")\n",
    "        \n",
    "        # Solve using quadratic formula\n",
    "        trace = a + d\n",
    "        det = a*d - b*c\n",
    "        discriminant = trace**2 - 4*det\n",
    "        \n",
    "        if discriminant >= 0:\n",
    "            lambda1 = (trace + np.sqrt(discriminant)) / 2\n",
    "            lambda2 = (trace - np.sqrt(discriminant)) / 2\n",
    "            print(f\"   Solutions: Œª‚ÇÅ = {lambda1:.3f}, Œª‚ÇÇ = {lambda2:.3f}\")\n",
    "        else:\n",
    "            print(f\"   Solutions: Complex eigenvalues (discriminant = {discriminant:.3f})\")\n",
    "        \n",
    "        # Verify with NumPy\n",
    "        eigenvals_numpy = np.linalg.eigvals(problem['matrix'])\n",
    "        print(f\"   ‚úÖ NumPy verification: {eigenvals_numpy}\")\n",
    "        print()\n",
    "\n",
    "eigenvalue_practice()\n",
    "\n",
    "print(\"üéì Learning Tips for Eigenvalue Calculations:\")\n",
    "print(\"1. Start with the characteristic polynomial: det(A - ŒªI) = 0\")\n",
    "print(\"2. For 2√ó2: Use Œª¬≤ - (trace)Œª + (determinant) = 0\")\n",
    "print(\"3. Solve the quadratic equation\")\n",
    "print(\"4. Substitute eigenvalues back to find eigenvectors\")\n",
    "print(\"5. Always verify your results!\")\n",
    "print(\"\\nüíª Remember: For real applications, use computational tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896faad5",
   "metadata": {},
   "source": [
    "## üéØ Summary: From Geometry to Calculation\n",
    "\n",
    "### The Complete Algorithm\n",
    "\n",
    "We've learned how to **systematically calculate** eigenvalues and eigenvectors:\n",
    "\n",
    "| **Step** | **Mathematical Operation** | **Purpose** |\n",
    "|----------|---------------------------|-------------|\n",
    "| **1** | Start with $A\\mathbf{x} = \\lambda\\mathbf{x}$ | Define the eigenvalue problem |\n",
    "| **2** | Rearrange to $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$ | Standard form |\n",
    "| **3** | Set $\\det(A - \\lambda I) = 0$ | Find eigenvalues |\n",
    "| **4** | Solve characteristic polynomial | Get values of $\\lambda$ |\n",
    "| **5** | For each $\\lambda$, solve $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$ | Find eigenvectors |\n",
    "\n",
    "### Key Mathematical Insights\n",
    "\n",
    "1. **Eigenvalues** come from solving the **characteristic polynomial**\n",
    "2. **Eigenvectors** come from solving the **null space** of $(A - \\lambda I)$\n",
    "3. **2√ó2 matrices** ‚Üí **Quadratic equations** (solvable by hand)\n",
    "4. **Larger matrices** ‚Üí **Higher-degree polynomials** (need computers)\n",
    "\n",
    "### The Characteristic Polynomial Pattern\n",
    "\n",
    "For any 2√ó2 matrix $\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$:\n",
    "\n",
    "$$\\lambda^2 - (a + d)\\lambda + (ad - bc) = 0$$\n",
    "\n",
    "Where:\n",
    "- **$(a + d)$** = **trace** of the matrix\n",
    "- **$(ad - bc)$** = **determinant** of the matrix\n",
    "\n",
    "### When Real Eigenvalues Don't Exist\n",
    "\n",
    "- **Rotations** (except 180¬∞) have complex eigenvalues\n",
    "- Complex eigenvalues mean **no real eigenvectors**\n",
    "- This matches our geometric intuition!\n",
    "\n",
    "### Computational Reality\n",
    "\n",
    "**For practical applications**:\n",
    "- ‚úÖ **Understand the concepts** geometrically and algebraically\n",
    "- ‚úÖ **Use computational tools** (NumPy, MATLAB, etc.)\n",
    "- ‚úÖ **Interpret results** in context of your problem\n",
    "- ‚ùå **Don't calculate by hand** for matrices larger than 2√ó2\n",
    "\n",
    "### Looking Ahead\n",
    "\n",
    "Next, we'll explore what happens when we use **eigenvectors as a basis** - this leads to powerful applications like:\n",
    "- **Principal Component Analysis (PCA)**\n",
    "- **Spectral decomposition**\n",
    "- **Diagonalization**\n",
    "\n",
    "The journey from geometric intuition ‚Üí algebraic formulation ‚Üí computational implementation is complete! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
